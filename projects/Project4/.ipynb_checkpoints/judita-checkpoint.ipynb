{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import concurrent.futures\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the initial 'album' website \n",
    "url = 'https://www.lyrics.com/artist/Lenny-Kravitz/4708'\n",
    "req = requests.get(url)\n",
    "html = req.content\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'a'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4dbaac6d3eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#soup.find_all('h3', attrs={'class': 'mob-hidden'})[1].text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#for entry in soup.find_all('h3', attrs={'class': 'mob-hidden'})[1:]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tbody'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'tal qx'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#[tag.a('href') for tag in soup.find_all('strong')[1:-3]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2079\u001b[0m         \u001b[0;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m         raise AttributeError(\n\u001b[0;32m-> 2081\u001b[0;31m             \u001b[0;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: ResultSet object has no attribute 'a'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "#Find all song's links in 'album' site - these can be found under\n",
    " #the 'strong' tab, and 'a' tab\n",
    "for entry in soup.find(\"tbody\", {\"class\": \"tal qx\"}).find('a', href=True):\n",
    "soup.find_all('h3', attrs={'class': 'mob-hidden'})[1].text\n",
    "for entry in soup.find_all('h3', attrs={'class': 'mob-hidden'})[1:]:\n",
    "soup.find_all('tbody', {'class': 'tal qx'}).a.get('href')\n",
    "[tag.a('href') for tag in soup.find_all('strong')[1:-3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-6fc02923ec02>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-6fc02923ec02>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    links = for entry in soup.find_all(\"tbody\", {\"class\": \"tal qx\"}).find_all('a', href=True)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def getLyrics(url):\n",
    "    url = HOST + url # songs are found on the HOST website\n",
    "    # Parse 'song' site\n",
    "    req = requests.get(url)\n",
    "    html = req.content\n",
    "    soup = BeautifulSoup(html ,'html.parser')\n",
    "    # Obtain the lyrics, which can be found under the 'pre' tab\n",
    "    return soup.find('pre').text\n",
    "\n",
    "# Use multi-threading for faster performance - I'll give a small run down:\n",
    "# max_workers = number of threads - we use an individual thread for each song\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=len(links)) as executor:\n",
    "    # for every song...\n",
    "    for j in range(len(links)):\n",
    "        # run the 'getLyrics' method on an individual thread and get the lyrics\n",
    "        lyrics = executor.submit(getLyrics, links[j]).result()\n",
    "        # do whatever with the lyrics ... I simply printed them\n",
    "        print(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas\n",
    "\n",
    "url = \"https://www.lyrics.com/album/3769520/Now+20th+Anniversary%2C+Vol.+2\"\n",
    "req = requests.get(url)\n",
    "html = req.content\n",
    "soup = BeautifulSoup(html , 'html.parser')\n",
    "\n",
    "tags = soup.find_all('strong')\n",
    "name = \"\"\n",
    "Length = len(tags)\n",
    "Length = Length - 3 # because it gives extra things\n",
    "newUrl = \"https://www.lyrics.com/lyric/35873930/\"\n",
    "for index in range(1 , Length):\n",
    "    SongName = tags[index].text.replace(\" \",\"\")\n",
    "    FileName = tags[index].text + \".txt\"\n",
    "    newFetechedUrl = newUrl + SongName\n",
    "#    print(newFetechedUrl)\n",
    "    req1 = requests.get(newFetechedUrl)\n",
    "    html1 = req1.content\n",
    "    soup1 = BeautifulSoup(html1, 'html.parser')\n",
    "    Lyrics = soup1.find_all(\"pre\", {\"id\": \"lyric-body-text\"})\n",
    "    print(Lyrics[0].text)\n",
    "    req2 = requests.get(url)\n",
    "    html2 = req2.content\n",
    "    soup2 = BeautifulSoup(html2, 'html.parser')\n",
    "    tags = soup2.find_all('strong')\n",
    "#    print(tags[index].text.replace(\" \",\"\"))\n",
    "    File = open(FileName,\"w\")\n",
    "    File.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
